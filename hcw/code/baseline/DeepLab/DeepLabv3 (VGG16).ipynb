{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#하이퍼파라미터-세팅-및-seed-고정\" data-toc-modified-id=\"하이퍼파라미터-세팅-및-seed-고정-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>하이퍼파라미터 세팅 및 seed 고정</a></span></li><li><span><a href=\"#학습-데이터-EDA\" data-toc-modified-id=\"학습-데이터-EDA-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>학습 데이터 EDA</a></span></li><li><span><a href=\"#데이터-전처리-함수-정의-(Dataset)\" data-toc-modified-id=\"데이터-전처리-함수-정의-(Dataset)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>데이터 전처리 함수 정의 (Dataset)</a></span></li><li><span><a href=\"#Dataset-정의-및-DataLoader-할당\" data-toc-modified-id=\"Dataset-정의-및-DataLoader-할당-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Dataset 정의 및 DataLoader 할당</a></span><ul class=\"toc-item\"><li><span><a href=\"#데이터-샘플-시각화-(Show-example-image-and-mask)\" data-toc-modified-id=\"데이터-샘플-시각화-(Show-example-image-and-mask)-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>데이터 샘플 시각화 (Show example image and mask)</a></span></li></ul></li><li><span><a href=\"#baseline-model\" data-toc-modified-id=\"baseline-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>baseline model</a></span><ul class=\"toc-item\"><li><span><a href=\"#[TODO]-코드-구현-DeepLabv3-\" data-toc-modified-id=\"[TODO]-코드-구현-DeepLabv3--5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span><font color=\"red\">[TODO] 코드 구현 DeepLabv3 </font></a></span></li></ul></li><li><span><a href=\"#train,-validation,-test-함수-정의\" data-toc-modified-id=\"train,-validation,-test-함수-정의-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>train, validation, test 함수 정의</a></span></li><li><span><a href=\"#모델-저장-함수-정의\" data-toc-modified-id=\"모델-저장-함수-정의-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>모델 저장 함수 정의</a></span></li><li><span><a href=\"#모델-생성-및-Loss-function,-Optimizer-정의\" data-toc-modified-id=\"모델-생성-및-Loss-function,-Optimizer-정의-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>모델 생성 및 Loss function, Optimizer 정의</a></span></li><li><span><a href=\"#저장된-model-불러오기-(학습된-이후)\" data-toc-modified-id=\"저장된-model-불러오기-(학습된-이후)-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>저장된 model 불러오기 (학습된 이후)</a></span></li><li><span><a href=\"#submission을-위한-test-함수-정의\" data-toc-modified-id=\"submission을-위한-test-함수-정의-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>submission을 위한 test 함수 정의</a></span></li><li><span><a href=\"#submission.csv-생성\" data-toc-modified-id=\"submission.csv-생성-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>submission.csv 생성</a></span></li><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/ml/code\n"
     ]
    }
   ],
   "source": [
    "cd code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations==0.5.2 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (0.5.2)\n",
      "Requirement already satisfied: anyio==2.2.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (2.2.0)\n",
      "Requirement already satisfied: argon2-cffi==20.1.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (20.1.0)\n",
      "Requirement already satisfied: async-generator==1.10 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (1.10)\n",
      "Requirement already satisfied: attrs==20.3.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (20.3.0)\n",
      "Requirement already satisfied: Babel==2.9.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (2.9.0)\n",
      "Requirement already satisfied: backcall==0.2.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: bcrypt==3.2.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (3.2.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.9.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (4.9.1)\n",
      "Requirement already satisfied: bleach==3.3.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 10)) (3.3.0)\n",
      "Requirement already satisfied: boto3==1.17.56 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 11)) (1.17.56)\n",
      "Requirement already satisfied: botocore==1.20.56 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 12)) (1.20.56)\n",
      "Requirement already satisfied: certifi==2020.12.5 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 13)) (2020.12.5)\n",
      "Requirement already satisfied: cffi==1.14.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 14)) (1.14.0)\n",
      "Requirement already satisfied: chardet==3.0.4 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 15)) (3.0.4)\n",
      "Requirement already satisfied: conda==4.8.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 16)) (4.8.3)\n",
      "Requirement already satisfied: conda-build==3.18.11 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 17)) (3.18.11)\n",
      "Requirement already satisfied: conda-package-handling==1.7.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 18)) (1.7.0)\n",
      "Requirement already satisfied: cryptography==2.9.2 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 19)) (2.9.2)\n",
      "Requirement already satisfied: cycler==0.10.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 20)) (0.10.0)\n",
      "Requirement already satisfied: Cython==0.29.23 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 21)) (0.29.23)\n",
      "Requirement already satisfied: decorator==4.4.2 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 22)) (4.4.2)\n",
      "Requirement already satisfied: defusedxml==0.7.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 23)) (0.7.1)\n",
      "Requirement already satisfied: deprecation==2.1.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 24)) (2.1.0)\n",
      "Requirement already satisfied: efficientnet-pytorch==0.6.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 25)) (0.6.3)\n",
      "Requirement already satisfied: entrypoints==0.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 26)) (0.3)\n",
      "Requirement already satisfied: filelock==3.0.12 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 27)) (3.0.12)\n",
      "Requirement already satisfied: gevent==21.1.2 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 28)) (21.1.2)\n",
      "Requirement already satisfied: glob2==0.7 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 29)) (0.7)\n",
      "Requirement already satisfied: greenlet==1.0.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 30)) (1.0.0)\n",
      "Requirement already satisfied: idna==2.9 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 31)) (2.9)\n",
      "Requirement already satisfied: imageio==2.9.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 32)) (2.9.0)\n",
      "Requirement already satisfied: imgaug==0.4.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 33)) (0.4.0)\n",
      "Requirement already satisfied: importlib-metadata==4.0.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 34)) (4.0.1)\n",
      "Requirement already satisfied: inotify-simple==1.2.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 35)) (1.2.1)\n",
      "Requirement already satisfied: ipykernel==5.5.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 36)) (5.5.3)\n",
      "Requirement already satisfied: ipython==7.16.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 37)) (7.16.1)\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 38)) (0.2.0)\n",
      "Requirement already satisfied: ipywidgets==7.6.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 39)) (7.6.3)\n",
      "Requirement already satisfied: jedi==0.17.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 40)) (0.17.1)\n",
      "Requirement already satisfied: Jinja2==2.11.2 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 41)) (2.11.2)\n",
      "Requirement already satisfied: jmespath==0.10.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 42)) (0.10.0)\n",
      "Requirement already satisfied: json5==0.9.4 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 43)) (0.9.4)\n",
      "Requirement already satisfied: jsonschema==3.2.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 44)) (3.2.0)\n",
      "Requirement already satisfied: jupyter-client==6.1.12 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 45)) (6.1.12)\n",
      "Requirement already satisfied: jupyter-core==4.7.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 46)) (4.7.1)\n",
      "Requirement already satisfied: jupyter-packaging==0.9.2 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 47)) (0.9.2)\n",
      "Requirement already satisfied: jupyter-server==1.6.4 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 48)) (1.6.4)\n",
      "Requirement already satisfied: jupyterlab==3.0.14 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 49)) (3.0.14)\n",
      "Requirement already satisfied: jupyterlab-pygments==0.1.2 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 50)) (0.1.2)\n",
      "Requirement already satisfied: jupyterlab-server==2.4.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 51)) (2.4.0)\n",
      "Requirement already satisfied: jupyterlab-widgets==1.0.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 52)) (1.0.0)\n",
      "Requirement already satisfied: kiwisolver==1.3.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 53)) (1.3.1)\n",
      "Requirement already satisfied: libarchive-c==2.9 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 54)) (2.9)\n",
      "Requirement already satisfied: MarkupSafe==1.1.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 55)) (1.1.1)\n",
      "Requirement already satisfied: matplotlib==3.0.2 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 56)) (3.0.2)\n",
      "Requirement already satisfied: mistune==0.8.4 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 57)) (0.8.4)\n",
      "Requirement already satisfied: mkl-fft==1.1.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 58)) (1.1.0)\n",
      "Requirement already satisfied: mkl-random==1.1.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 59)) (1.1.1)\n",
      "Requirement already satisfied: mkl-service==2.3.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 60)) (2.3.0)\n",
      "Requirement already satisfied: munch==2.5.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 61)) (2.5.0)\n",
      "Requirement already satisfied: nbclassic==0.2.7 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 62)) (0.2.7)\n",
      "Requirement already satisfied: nbclient==0.5.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 63)) (0.5.3)\n",
      "Requirement already satisfied: nbconvert==6.0.7 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 64)) (6.0.7)\n",
      "Requirement already satisfied: nbformat==5.1.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 65)) (5.1.3)\n",
      "Requirement already satisfied: nest-asyncio==1.5.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 66)) (1.5.1)\n",
      "Requirement already satisfied: networkx==2.5.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 67)) (2.5.1)\n",
      "Requirement already satisfied: notebook==6.3.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 68)) (6.3.0)\n",
      "Requirement already satisfied: numpy==1.19.5 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 69)) (1.19.5)\n",
      "Requirement already satisfied: olefile==0.46 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 70)) (0.46)\n",
      "Requirement already satisfied: opencv-python==4.2.0.34 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 71)) (4.2.0.34)\n",
      "Requirement already satisfied: opencv-python-headless==4.5.1.48 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 72)) (4.5.1.48)\n",
      "Requirement already satisfied: packaging==20.9 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 73)) (20.9)\n",
      "Requirement already satisfied: pandas==1.1.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 74)) (1.1.1)\n",
      "Requirement already satisfied: pandocfilters==1.4.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 75)) (1.4.3)\n",
      "Requirement already satisfied: paramiko==2.7.2 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 76)) (2.7.2)\n",
      "Requirement already satisfied: parso==0.7.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 77)) (0.7.0)\n",
      "Requirement already satisfied: pexpect==4.8.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 78)) (4.8.0)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 79)) (0.7.5)\n",
      "Requirement already satisfied: Pillow==7.2.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 80)) (7.2.0)\n",
      "Requirement already satisfied: pkginfo==1.5.0.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 81)) (1.5.0.1)\n",
      "Requirement already satisfied: pretrainedmodels==0.7.4 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 82)) (0.7.4)\n",
      "Requirement already satisfied: prometheus-client==0.10.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 83)) (0.10.1)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.5 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 84)) (3.0.5)\n",
      "Requirement already satisfied: protobuf==3.15.8 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 85)) (3.15.8)\n",
      "Requirement already satisfied: psutil==5.7.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 86)) (5.7.0)\n",
      "Requirement already satisfied: ptyprocess==0.6.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 87)) (0.6.0)\n",
      "Requirement already satisfied: pycocotools==2.0.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 88)) (2.0.0)\n",
      "Requirement already satisfied: pycosat==0.6.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 89)) (0.6.3)\n",
      "Requirement already satisfied: pycparser==2.20 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 90)) (2.20)\n",
      "Requirement already satisfied: Pygments==2.6.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 91)) (2.6.1)\n",
      "Requirement already satisfied: PyNaCl==1.4.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 92)) (1.4.0)\n",
      "Requirement already satisfied: pyOpenSSL==19.1.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 93)) (19.1.0)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 94)) (2.4.7)\n",
      "Requirement already satisfied: pyrsistent==0.17.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 95)) (0.17.3)\n",
      "Requirement already satisfied: PySocks==1.7.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 96)) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 97)) (2.8.1)\n",
      "Requirement already satisfied: pytz==2020.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 98)) (2020.1)\n",
      "Requirement already satisfied: PyWavelets==1.1.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 99)) (1.1.1)\n",
      "Requirement already satisfied: PyYAML==5.3.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 100)) (5.3.1)\n",
      "Requirement already satisfied: pyzmq==22.0.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 101)) (22.0.3)\n",
      "Requirement already satisfied: requests==2.23.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 102)) (2.23.0)\n",
      "Requirement already satisfied: retrying==1.3.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 103)) (1.3.3)\n",
      "Requirement already satisfied: ruamel-yaml==0.15.87 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 104)) (0.15.87)\n",
      "Requirement already satisfied: s3transfer==0.4.2 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 105)) (0.4.2)\n",
      "Requirement already satisfied: sagemaker-training==3.9.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 106)) (3.9.1)\n",
      "Requirement already satisfied: scikit-image==0.18.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 107)) (0.18.1)\n",
      "Requirement already satisfied: scipy==1.6.2 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 108)) (1.6.2)\n",
      "Requirement already satisfied: seaborn==0.9.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 109)) (0.9.0)\n",
      "Requirement already satisfied: segmentation-models-pytorch==0.1.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 110)) (0.1.3)\n",
      "Requirement already satisfied: Send2Trash==1.5.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 111)) (1.5.0)\n",
      "Requirement already satisfied: Shapely==1.7.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 112)) (1.7.1)\n",
      "Requirement already satisfied: six==1.14.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 113)) (1.14.0)\n",
      "Requirement already satisfied: sniffio==1.2.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 114)) (1.2.0)\n",
      "Requirement already satisfied: soupsieve==2.0.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 115)) (2.0.1)\n",
      "Requirement already satisfied: terminado==0.9.4 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 116)) (0.9.4)\n",
      "Requirement already satisfied: testpath==0.4.4 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 117)) (0.4.4)\n",
      "Requirement already satisfied: tifffile==2021.4.8 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 118)) (2021.4.8)\n",
      "Requirement already satisfied: timm==0.3.2 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 119)) (0.3.2)\n",
      "Requirement already satisfied: tomlkit==0.7.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 120)) (0.7.0)\n",
      "Requirement already satisfied: torch==1.4.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 121)) (1.4.0)\n",
      "Requirement already satisfied: torchvision==0.5.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 122)) (0.5.0)\n",
      "Requirement already satisfied: tornado==6.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 123)) (6.1)\n",
      "Requirement already satisfied: tqdm==4.60.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 124)) (4.60.0)\n",
      "Requirement already satisfied: traitlets==4.3.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 125)) (4.3.3)\n",
      "Requirement already satisfied: typing-extensions==3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 126)) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3==1.25.8 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 127)) (1.25.8)\n",
      "Requirement already satisfied: wcwidth==0.2.5 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 128)) (0.2.5)\n",
      "Requirement already satisfied: webencodings==0.5.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 129)) (0.5.1)\n",
      "Requirement already satisfied: Werkzeug==1.0.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 130)) (1.0.1)\n",
      "Requirement already satisfied: widgetsnbextension==3.5.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 131)) (3.5.1)\n",
      "Requirement already satisfied: zipp==3.4.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 132)) (3.4.1)\n",
      "Requirement already satisfied: zope.event==4.5.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 133)) (4.5.0)\n",
      "Requirement already satisfied: zope.interface==5.4.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 134)) (5.4.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from conda-build==3.18.11->-r requirements.txt (line 17)) (46.4.0.post20200518)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from jupyter-packaging==0.9.2->-r requirements.txt (line 47)) (0.34.2)\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (from sagemaker-training==3.9.1->-r requirements.txt (line 106)) (20.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]      \n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Fetched 252 kB in 2s (135 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libsm6 is already the newest version (2:1.2.2-1).\n",
      "libxext6 is already the newest version (2:1.3.3-1).\n",
      "libxrender-dev is already the newest version (1:0.9.10-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (4.2.0.34)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from opencv-python) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y libsm6 libxext6 libxrender-dev\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T10:34:47.826930Z",
     "start_time": "2021-04-18T10:34:45.406686Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import label_accuracy_score\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 전처리를 위한 라이브러리\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "plt.rcParams['axes.grid'] = False\n",
    "\n",
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"   # GPU 사용 가능 여부에 따라 device 정보 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 세팅 및 seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T10:34:47.841930Z",
     "start_time": "2021-04-18T10:34:47.827931Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8   # Mini-batch size\n",
    "num_epochs = 20\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T10:34:47.856930Z",
     "start_time": "2021-04-18T10:34:47.842931Z"
    }
   },
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 21\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "# torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T10:34:51.381961Z",
     "start_time": "2021-04-18T10:34:47.857930Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "dataset_path = '../input/data'\n",
    "anns_file_path = dataset_path + '/' + 'train.json'\n",
    "\n",
    "# Read annotations\n",
    "with open(anns_file_path, 'r') as f:\n",
    "    dataset = json.loads(f.read())\n",
    "\n",
    "categories = dataset['categories']\n",
    "anns = dataset['annotations']\n",
    "imgs = dataset['images']\n",
    "nr_cats = len(categories)\n",
    "nr_annotations = len(anns)\n",
    "nr_images = len(imgs)\n",
    "\n",
    "# Load categories and super categories\n",
    "cat_names = []\n",
    "super_cat_names = []\n",
    "super_cat_ids = {}\n",
    "super_cat_last_name = ''\n",
    "nr_super_cats = 0\n",
    "for cat_it in categories:\n",
    "    cat_names.append(cat_it['name'])\n",
    "    super_cat_name = cat_it['supercategory']\n",
    "    # Adding new supercat\n",
    "    if super_cat_name != super_cat_last_name:\n",
    "        super_cat_names.append(super_cat_name)\n",
    "        super_cat_ids[super_cat_name] = nr_super_cats\n",
    "        super_cat_last_name = super_cat_name\n",
    "        nr_super_cats += 1\n",
    "\n",
    "print('Number of super categories:', nr_super_cats)\n",
    "print('Number of categories:', nr_cats)\n",
    "print('Number of annotations:', nr_annotations)\n",
    "print('Number of images:', nr_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T10:34:51.546964Z",
     "start_time": "2021-04-18T10:34:51.382969Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count annotations\n",
    "cat_histogram = np.zeros(nr_cats,dtype=int)\n",
    "for ann in anns:\n",
    "    cat_histogram[ann['category_id']] += 1\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({'Categories': cat_names, 'Number of annotations': cat_histogram})\n",
    "df = df.sort_values('Number of annotations', 0, False)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.title(\"category distribution of train set \")\n",
    "plot_1 = sns.barplot(x=\"Number of annotations\", y=\"Categories\", data=df, label=\"Total\", color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T10:34:51.561965Z",
     "start_time": "2021-04-18T10:34:51.547969Z"
    }
   },
   "outputs": [],
   "source": [
    "# category labeling \n",
    "sorted_temp_df = df.sort_index()\n",
    "\n",
    "# background = 0 에 해당되는 label 추가 후 기존들을 모두 label + 1 로 설정\n",
    "sorted_df = pd.DataFrame([\"Backgroud\"], columns = [\"Categories\"])\n",
    "sorted_df = sorted_df.append(sorted_temp_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T10:34:51.576961Z",
     "start_time": "2021-04-18T10:34:51.562964Z"
    }
   },
   "outputs": [],
   "source": [
    "# class (Categories) 에 따른 index 확인 (0~11 : 총 12개)\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 함수 정의 (Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T10:34:52.693328Z",
     "start_time": "2021-04-18T10:34:52.681328Z"
    }
   },
   "outputs": [],
   "source": [
    "category_names = list(sorted_df.Categories)\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\"\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"COCO format\"\"\"\n",
    "    def __init__(self, data_dir, mode = 'train', transform = None):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.coco = COCO(data_dir)\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        images = cv2.imread(os.path.join(dataset_path, image_infos['file_name']))\n",
    "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        images /= 255.0\n",
    "        \n",
    "        if (self.mode in ('train', 'val')):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            # Load the categories in a variable\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id + 1\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            # Unknown = 1, General trash = 2, ... , Cigarette = 11\n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i]['category_id'], cats)\n",
    "                pixel_value = category_names.index(className)\n",
    "                masks = np.maximum(self.coco.annToMask(anns[i])*pixel_value, masks)\n",
    "            masks = masks.astype(np.float32)\n",
    "\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "            \n",
    "            return images, masks, image_infos\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "            \n",
    "            return images, image_infos\n",
    "    \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 정의 및 DataLoader 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T10:34:58.823175Z",
     "start_time": "2021-04-18T10:34:54.106233Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train.json / validation.json / test.json 디렉토리 설정\n",
    "train_path = dataset_path + '/train.json'\n",
    "val_path = dataset_path + '/val.json'\n",
    "test_path = dataset_path + '/test.json'\n",
    "\n",
    "# collate_fn needs for batch\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_transform = A.Compose([\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "                          ToTensorV2()\n",
    "                          ])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                           ToTensorV2()\n",
    "                           ])\n",
    "\n",
    "# create own Dataset 1 (skip)\n",
    "# validation set을 직접 나누고 싶은 경우\n",
    "# random_split 사용하여 data set을 8:2 로 분할\n",
    "# train_size = int(0.8*len(dataset))\n",
    "# val_size = int(len(dataset)-train_size)\n",
    "# dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=transform)\n",
    "# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# create own Dataset 2\n",
    "# train dataset\n",
    "train_dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=train_transform)\n",
    "\n",
    "# validation dataset\n",
    "val_dataset = CustomDataLoader(data_dir=val_path, mode='val', transform=val_transform)\n",
    "\n",
    "# test dataset\n",
    "test_dataset = CustomDataLoader(data_dir=test_path, mode='test', transform=test_transform)\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=4,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                           drop_last = True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=4,\n",
    "                                         collate_fn=collate_fn,\n",
    "                                         drop_last = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          num_workers=4,\n",
    "                                          collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 샘플 시각화 (Show example image and mask)\n",
    "\n",
    "- `train_loader` \n",
    "- `val_loader` \n",
    "- `test_loader` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T17:59:26.346907Z",
     "start_time": "2021-04-16T17:59:26.002907Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_loader의 output 결과(image 및 mask) 확인\n",
    "for imgs, masks, image_infos in train_loader:\n",
    "    image_infos = image_infos[0]\n",
    "    temp_images = imgs\n",
    "    temp_masks = masks\n",
    "    \n",
    "    break\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 12))\n",
    "\n",
    "print('image shape:', list(temp_images[0].shape))\n",
    "print('mask shape: ', list(temp_masks[0].shape))\n",
    "print('Unique values, category of transformed mask : \\n', [{int(i),category_names[int(i)]} for i in list(np.unique(temp_masks[0]))])\n",
    "\n",
    "ax1.imshow(temp_images[0].permute([1,2,0]))\n",
    "ax1.grid(False)\n",
    "ax1.set_title(\"input image : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "ax2.imshow(temp_masks[0])\n",
    "ax2.grid(False)\n",
    "ax2.set_title(\"masks : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T13:50:43.557278Z",
     "start_time": "2021-04-16T13:50:43.194005Z"
    }
   },
   "outputs": [],
   "source": [
    "# val_loader의 output 결과(image 및 mask) 확인\n",
    "for imgs, masks, image_infos in val_loader:\n",
    "    image_infos = image_infos[0]\n",
    "    temp_images = imgs\n",
    "    temp_masks = masks\n",
    "    \n",
    "    break\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 12))\n",
    "\n",
    "print('image shape:', list(temp_images[0].shape))\n",
    "print('mask shape: ', list(temp_masks[0].shape))\n",
    "\n",
    "print('Unique values, category of transformed mask : \\n', [{int(i),category_names[int(i)]} for i in list(np.unique(temp_masks[0]))])\n",
    "\n",
    "ax1.imshow(temp_images[0].permute([1,2,0]))\n",
    "ax1.grid(False)\n",
    "ax1.set_title(\"input image : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "ax2.imshow(temp_masks[0])\n",
    "ax2.grid(False)\n",
    "ax2.set_title(\"masks : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T13:51:11.569325Z",
     "start_time": "2021-04-16T13:51:11.377327Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_loader의 output 결과(image 및 mask) 확인\n",
    "for imgs, image_infos in test_loader:\n",
    "    image_infos = image_infos[0]\n",
    "    temp_images = imgs\n",
    "    # temp_masks = masks\n",
    "    \n",
    "    break\n",
    "\n",
    "fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "\n",
    "print('image shape:', list(temp_images[0].shape))\n",
    "\n",
    "ax1.imshow(temp_images[0].permute([1,2,0]))\n",
    "ax1.grid(False)\n",
    "ax1.set_title(\"input image : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline model\n",
    "\n",
    "### <font color='red'>[TODO] 코드 구현 DeepLabv3 </font>\n",
    "\n",
    "> DeepLabv3의 backbone은 원래 resnet이지만 편의상 vgg로 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def conv3x3_relu(in_ch, out_ch, rate=1):\n",
    "    conv3x3_relu = nn.Sequential(nn.Conv2d(in_ch, \n",
    "                                           out_ch,\n",
    "                                           kernel_size=3, \n",
    "                                           stride=1,\n",
    "                                           padding=rate,\n",
    "                                           dilation=rate),\n",
    "                                 nn.ReLU())\n",
    "    return conv3x3_relu\n",
    "\n",
    "\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        '''\n",
    "        [TODO]\n",
    "\n",
    "        ''' \n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        [TODO]\n",
    "\n",
    "        '''\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASPPConv(nn.Module):\n",
    "    def __init__(self, inplanes, outplanes, kernel_size, padding, dilation):\n",
    "        super(ASPPConv, self).__init__()\n",
    "        '''\n",
    "        [TODO]\n",
    "\n",
    "        ''' \n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        [TODO]\n",
    "\n",
    "        '''\n",
    "        return out \n",
    "    \n",
    "    \n",
    "class ASPPPooling(nn.Module):\n",
    "    def __init__(self, inplanes, outplanes):\n",
    "        super(ASPPPooling, self).__init__()\n",
    "        '''\n",
    "        [TODO]\n",
    "\n",
    "        ''' \n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        [TODO]\n",
    "\n",
    "        '''\n",
    "        \n",
    "        return out\n",
    "\n",
    "    \n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, inplanes, outplanes):\n",
    "        super(ASPP, self).__init__()\n",
    "        '''\n",
    "        [TODO]\n",
    "\n",
    "        ''' \n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        [TODO]\n",
    "\n",
    "        '''\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabHead(nn.Sequential):\n",
    "    def __init__(self, ch, out_ch, n_classes):\n",
    "        super(DeepLabHead, self).__init__()\n",
    "        '''\n",
    "        [TODO]\n",
    "\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T08:45:20.394457Z",
     "start_time": "2021-04-24T08:45:20.344136Z"
    }
   },
   "outputs": [],
   "source": [
    "class DeepLabV3(nn.Sequential):\n",
    "    def __init__(self, n_classes, n_blocks, atrous_rates):\n",
    "        super(DeepLabV3, self).__init__()\n",
    "        '''\n",
    "        [TODO]\n",
    "\n",
    "        ''' \n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        [TODO]\n",
    "\n",
    "        '''\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T16:16:11.634792Z",
     "start_time": "2021-04-18T16:16:05.875817Z"
    }
   },
   "outputs": [],
   "source": [
    "# 구현된 model에 임의의 input을 넣어 output이 잘 나오는지 test\n",
    "model = DeepLabV3(n_classes=12, n_blocks=[3, 4, 23, 3], atrous_rates=[6, 12, 18, 24])\n",
    "\n",
    "x = torch.randn([2, 3, 512, 512])\n",
    "print(\"input shape : \", x.shape)\n",
    "out = model(x).to(device)\n",
    "print(\"output shape : \", out.size())\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, validation, test 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T16:16:18.104200Z",
     "start_time": "2021-04-18T16:16:18.093174Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(num_epochs, model, data_loader, val_loader, criterion, optimizer, saved_dir, val_every, device):\n",
    "    print('Start training..')\n",
    "    best_loss = 9999999\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for step, (images, masks, _) in enumerate(data_loader):\n",
    "            images = torch.stack(images)       # (batch, channel, height, width)\n",
    "            masks = torch.stack(masks).long()  # (batch, channel, height, width)\n",
    "            \n",
    "            # gpu 연산을 위해 device 할당\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "                  \n",
    "            # inference\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # loss 계산 (cross entropy loss)\n",
    "            loss = criterion(outputs, masks)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # step 주기에 따른 loss 출력\n",
    "            if (step + 1) % 25 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n",
    "                    epoch+1, num_epochs, step+1, len(train_loader), loss.item()))\n",
    "        \n",
    "        # validation 주기에 따른 loss 출력 및 best model 저장\n",
    "        if (epoch + 1) % val_every == 0:\n",
    "            avrg_loss = validation(epoch + 1, model, val_loader, criterion, device)\n",
    "            if avrg_loss < best_loss:\n",
    "                print('Best performance at epoch: {}'.format(epoch + 1))\n",
    "                print('Save model in', saved_dir)\n",
    "                best_loss = avrg_loss\n",
    "                save_model(model, saved_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T16:16:18.285795Z",
     "start_time": "2021-04-18T16:16:18.267686Z"
    }
   },
   "outputs": [],
   "source": [
    "def validation(epoch, model, data_loader, criterion, device):\n",
    "    print('Start validation #{}'.format(epoch))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        cnt = 0\n",
    "        mIoU_list = []\n",
    "        for step, (images, masks, _) in enumerate(data_loader):\n",
    "            \n",
    "            images = torch.stack(images)       # (batch, channel, height, width)\n",
    "            masks = torch.stack(masks).long()  # (batch, channel, height, width)\n",
    "\n",
    "            images, masks = images.to(device), masks.to(device)            \n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            total_loss += loss\n",
    "            cnt += 1\n",
    "            \n",
    "            outputs = torch.argmax(outputs.squeeze(), dim=1).detach().cpu().numpy()\n",
    "\n",
    "            mIoU = label_accuracy_score(masks.detach().cpu().numpy(), outputs, n_class=12)[2]\n",
    "            mIoU_list.append(mIoU)\n",
    "            \n",
    "        avrg_loss = total_loss / cnt\n",
    "        print('Validation #{}  Average Loss: {:.4f}, mIoU: {:.4f}'.format(epoch, avrg_loss, np.mean(mIoU_list)))\n",
    "\n",
    "    return avrg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T16:16:18.909918Z",
     "start_time": "2021-04-18T16:16:18.898918Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 저장 함수 정의\n",
    "val_every = 1 \n",
    "\n",
    "saved_dir = './saved'\n",
    "if not os.path.isdir(saved_dir):                                                           \n",
    "    os.mkdir(saved_dir)\n",
    "    \n",
    "def save_model(model, saved_dir, file_name='DeepLabv3_best_model(vgg16).pt'):\n",
    "    check_point = {'net': model.state_dict()}\n",
    "    output_path = os.path.join(saved_dir, file_name)\n",
    "    torch.save(model.state_dict(), output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성 및 Loss function, Optimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T16:16:19.698902Z",
     "start_time": "2021-04-18T16:16:19.694902Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loss function 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer 정의\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-04-18T16:16:20.331Z"
    }
   },
   "outputs": [],
   "source": [
    "train(num_epochs, model, train_loader, val_loader, criterion, optimizer, saved_dir, val_every, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 저장된 model 불러오기 (학습된 이후) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T19:44:21.050200Z",
     "start_time": "2021-04-16T19:44:20.802200Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# best model 저장된 경로\n",
    "model_path = './saved/DeepLabv3_best_model(vgg16).pt'\n",
    "\n",
    "# best model 불러오기\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# 추론을 실행하기 전에는 반드시 설정 (batch normalization, dropout 를 평가 모드로 설정)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T19:44:24.939227Z",
     "start_time": "2021-04-16T19:44:24.518228Z"
    }
   },
   "outputs": [],
   "source": [
    "# 첫번째 batch의 추론 결과 확인\n",
    "for imgs, image_infos in test_loader:\n",
    "    image_infos = image_infos\n",
    "    temp_images = imgs\n",
    "    \n",
    "    model.eval()\n",
    "    # inference\n",
    "    outs = model(torch.stack(temp_images).to(device))\n",
    "    oms = torch.argmax(outs.squeeze(), dim=1).detach().cpu().numpy()\n",
    "    \n",
    "    break\n",
    "\n",
    "i = 3\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\n",
    "\n",
    "print('Shape of Original Image :', list(temp_images[i].shape))\n",
    "print('Shape of Predicted : ', list(oms[i].shape))\n",
    "print('Unique values, category of transformed mask : \\n', [{int(i),category_names[int(i)]} for i in list(np.unique(oms[i]))])\n",
    "\n",
    "# Original image\n",
    "ax1.imshow(temp_images[i].permute([1,2,0]))\n",
    "ax1.grid(False)\n",
    "ax1.set_title(\"Original image : {}\".format(image_infos[i]['file_name']), fontsize = 15)\n",
    "\n",
    "# Predicted\n",
    "ax2.imshow(oms[i])\n",
    "ax2.grid(False)\n",
    "ax2.set_title(\"Predicted : {}\".format(image_infos[i]['file_name']), fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submission을 위한 test 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T19:44:27.469285Z",
     "start_time": "2021-04-16T19:44:27.456021Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, data_loader, device):\n",
    "    size = 256\n",
    "    transform = A.Compose([A.Resize(256, 256)])\n",
    "    print('Start prediction.')\n",
    "    model.eval()\n",
    "    \n",
    "    file_name_list = []\n",
    "    preds_array = np.empty((0, size*size), dtype=np.long)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, (imgs, image_infos) in enumerate(test_loader):\n",
    "\n",
    "            # inference (512 x 512)\n",
    "            outs = model(torch.stack(imgs).to(device))\n",
    "            oms = torch.argmax(outs.squeeze(), dim=1).detach().cpu().numpy()\n",
    "            \n",
    "            # resize (256 x 256)\n",
    "            temp_mask = []\n",
    "            for img, mask in zip(np.stack(temp_images), oms):\n",
    "                transformed = transform(image=img, mask=mask)\n",
    "                mask = transformed['mask']\n",
    "                temp_mask.append(mask)\n",
    "\n",
    "            oms = np.array(temp_mask)\n",
    "            \n",
    "            oms = oms.reshape([oms.shape[0], size*size]).astype(int)\n",
    "            preds_array = np.vstack((preds_array, oms))\n",
    "            \n",
    "            file_name_list.append([i['file_name'] for i in image_infos])\n",
    "    print(\"End prediction.\")\n",
    "    file_names = [y for x in file_name_list for y in x]\n",
    "    \n",
    "    return file_names, preds_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submission.csv 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T19:45:42.235310Z",
     "start_time": "2021-04-16T19:44:30.499016Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = test(model, test_loader, device)\n",
    "\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "submission.to_csv(\"./submission/Baseline_DeepLabv3(vgg16).csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "297.278px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
