{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5T_hO48Mt575"
   },
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "# from utils.loss import ComputeLoss\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# https://github.com/rwightman/efficientdet-pytorch/tree/master/effdet\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain\n",
    "from effdet.efficientdet import HeadNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "arQHgEmHt576"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    '''\n",
    "      data_dir: data가 존재하는 폴더 경로\n",
    "      transforms: data transform (resize, crop, Totensor, etc,,,)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, annotation, data_dir, transforms=None):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        # coco annotation 불러오기 (coco API)\n",
    "        self.coco = COCO(annotation)\n",
    "#         self.image_size = image_size\n",
    "        self.predictions = {\n",
    "            \"images\": self.coco.dataset[\"images\"].copy(),\n",
    "            \"categories\": self.coco.dataset[\"categories\"].copy(),\n",
    "            \"annotations\": None\n",
    "        }\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_info = self.coco.loadImgs(image_id)[0]\n",
    "        image = cv2.imread(os.path.join(self.data_dir, image_info['file_name']))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=image_info['id'])\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "        # boxes (x, y, w, h)\n",
    "        boxes = np.array([x['bbox'] for x in anns])\n",
    "\n",
    "        # boxes (x_min, y_min, x_max, y_max)\n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "        \n",
    "        # box별 label\n",
    "#         labels = list([x['category_id'] for x in anns])\n",
    "        labels = np.array([x['category_id'] for x in anns])\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        areas = np.array([x['area'] for x in anns])\n",
    "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
    "        \n",
    "        is_crowds = np.array([x['iscrowd'] for x in anns])\n",
    "        is_crowds = torch.as_tensor(is_crowds, dtype=torch.int64)\n",
    "        \n",
    "        segmentation = np.array([x['segmentation'] for x in anns], dtype=object)\n",
    "\n",
    "        \n",
    "        target = {'boxes': boxes, 'labels': labels, 'image_id': torch.tensor([index]), 'area': areas,\n",
    "                  'iscrowd': is_crowds}\n",
    "\n",
    "        # transform\n",
    "        if self.transforms:\n",
    "            # albumentaion을 거쳐 box가 사라지는 경우를 걸러내기 위해\n",
    "            while True:\n",
    "                sample = self.transforms(**{\n",
    "                    'image': image,\n",
    "                    'bboxes': target['boxes'],\n",
    "                    'labels': labels\n",
    "                })\n",
    "                if len(sample['bboxes']) > 0:\n",
    "                    image = sample['image']\n",
    "                    target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1,0)\n",
    "                    # efficientdet은 xyxy이 아니라 yxyx 형태로 받기 때문에 변경해줌\n",
    "                    target['boxes'][:,[0,1,2,3]] = target['boxes'][:,[1,0,3,2]] #yxyx: be warning\n",
    "                    target['labels'] = torch.tensor(sample['labels'])\n",
    "                break\n",
    "                \n",
    "        return image, target, image_id\n",
    "            \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W3cqcoNNt578"
   },
   "outputs": [],
   "source": [
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        A.Resize(512, 512),\n",
    "        A.Flip(p=0.5),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "\n",
    "\n",
    "def get_valid_transform(image_size):\n",
    "    return A.Compose([\n",
    "        A.Resize(image_size, image_size),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "816rgkc3t578"
   },
   "outputs": [],
   "source": [
    "class Averager:\n",
    "    def __init__(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "    def send(self, value):\n",
    "        self.current_total += value\n",
    "        self.iterations += 1\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        if self.iterations == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.0 * self.current_total / self.iterations\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from effdet import DetBenchPredict  #BenchTrain.py 파일에 같이 정의되어 있다,(공식 사이트 gitnub에)\n",
    "import gc\n",
    "\n",
    "def load_net(checkpoint_path, device):\n",
    "    \n",
    "    # config 파일 불러오기\n",
    "    config = get_efficientdet_config('tf_efficientdet_d3')\n",
    "    config.num_classes = 11\n",
    "    config..images_size = (512,512)\n",
    "    \n",
    "    config.soft_nms = False  #nms말고 soft nms를 적용할 것인지\n",
    "    config.max_det_per_image = 25  # max detection region의 개수\n",
    "    \n",
    "    net = EfficientDet(config, pretrained_backbone=True)  #pretrained weight도 같이 load\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes)  #class개수가 바꿔었기 때문에 새롭게 headNet을 정의해줘야한다.\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    \n",
    "    net = DetBenchPredict(net)\n",
    "    net.load_state_dict(checkpoint)\n",
    "    net.eval()\n",
    "    return net.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWL02o4kt579"
   },
   "outputs": [],
   "source": [
    "def valid_fn(val_data_loader, model, device, conf_thres=0.001, iou_thres=0.01):\n",
    "    outputs = []\n",
    "    for images, targets, image_ids in tqdm(val_data_loader):\n",
    "        # gpu 계산을 위해 image.to(device)\n",
    "        images = torch.stack(images) # bs,ch,w,h - 16,3,512,512\n",
    "        images = images.to(device).float()\n",
    "        oytput = model(images)\n",
    "        for out in output:\n",
    "            outputs.append({'boxes': out.detach().cpu().numpy()[:,:4],\n",
    "                            'scores': out.detach().cpu().numpy()[:,:4], \n",
    "                            'labels': out.detach().cpu().numpy()[:,-1]})  # 마지막에 label정보 가짐\n",
    "        \n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hf4A22QVt57_"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    data_dir = '../input/data'\n",
    "    annotation = '../input/data/val.json'\n",
    "    val_dataset = CustomDataset(annotation, data_dir, get_valid_transform())\n",
    "    epoch = 2\n",
    "    check_point = f'epoch_{epoch}.pth'\n",
    "    score_threshold = 0.1\n",
    "    val_data_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    print(device)\n",
    "    \n",
    "    model = load_net(checkpoint_path, device)\n",
    "    \n",
    "    outputs = valid_fn(val_data_loader, model, device)\n",
    "    \n",
    "    prediction_strings = []\n",
    "    file_names = []\n",
    "    coco = COCO(annotation)\n",
    "    for i, output in enumerate(outputs):\n",
    "        prediction_string = ''\n",
    "        image_info = coco.loadImgs(coco.getImgIds(imgIds=i))[0]\n",
    "        for box, score, label in zip(output['boxes'], output['scores'], output['labels']):\n",
    "            if score > score_threshold :\n",
    "                prediction_string += str(int(label)) + ' ' + str(score) + ' ' + str(box[0]) + ' ' + str(\n",
    "                    box[1]) + ' ' + str(box[2]) + ' ' + str(box[3]) + ' '\n",
    "        prediction_strings.append(prediction_string)\n",
    "        file_names.append(image_info['file_name'])\n",
    "        \n",
    "    submission = pd.DataFrame()\n",
    "    submission['PredictionString'] = prediction_strings\n",
    "    submission['image_id'] = file_names\n",
    "    submission.to_csv(f'submission_{epoch}.csv', index=None)\n",
    "    print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psA-p_rBt58A",
    "outputId": "08d3cbb3-fbf5-402d-d200-7303768090ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=3.84s)\n",
      "creating index...\n",
      "index created!\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [01:03<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.25s)\n",
      "creating index...\n",
      "index created!\n",
      "                                    PredictionString              image_id\n",
      "0  1 1.0 94.899994 76.549995 358.5 290.25 8 1.0 1...  batch_01_vt/0003.jpg\n",
      "1  6 1.0 -169.75 48.449997 313.95 345.15002 2 0.0...  batch_01_vt/0005.jpg\n",
      "2  6 1.0 -73.600006 -27.84999 339.0 390.05 4 1.0 ...  batch_01_vt/0006.jpg\n",
      "3  6 1.0 68.69998 -21.25 510.9 165.85 2 0.0021363...  batch_01_vt/0007.jpg\n",
      "4  1 1.0 -102.15 -46.199997 234.35 325.40002 2 0....  batch_01_vt/0010.jpg\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "yolov3_inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
